{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/DMcClarence/ICT303-Assignment1/blob/main/ICT303_Assignment1.ipynb",
      "authorship_tag": "ABX9TyPOhsAbKxBRfV50x7XhVIF5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sErBd01nhySo"
      },
      "outputs": [],
      "source": [
        "# Set Up\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loader\n",
        "class DataLoader():\n",
        "  def __init__(self, dir=\"MyDrive/data\", width=300, height=432):\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.root = dir\n",
        "\n",
        "  def load(self, dataset=\"/test\", batchSize=10, shuffle=True, workers=2):\n",
        "    transform = transforms.Compose([transforms.Resize((124, 124)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    dataset = datasets.ImageFolder(root=self.root + dataset, transform=transform)\n",
        "    dataset = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=shuffle, num_workers=workers)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "Hz6eIOSv9AIG"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, inputSize=124*124*3, outputSize=8, lr=0.01):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(inputSize, 1024),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(1024, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(512, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256, outputSize),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.lr = lr\n",
        "\n",
        "    # self.scheduler =\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)\n",
        "\n",
        "  def loss(self, y_hat, y):\n",
        "    # print(y, y_hat)\n",
        "    fn = nn.CrossEntropyLoss()\n",
        "    return fn(y_hat, y)\n",
        "\n",
        "  def configureOptimiser(self):\n",
        "    return torch.optim.Adam(self.parameters(), self.lr)"
      ],
      "metadata": {
        "id": "6VGMRhXnlKFi"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer Class\n",
        "class Trainer():\n",
        "  def __init__(self, nEpochs=3):\n",
        "    self.maxEpochs = nEpochs\n",
        "\n",
        "  def expLR(self, lr):\n",
        "    return lr * 0.95\n",
        "\n",
        "  # The fitting step\n",
        "  def fit(self, model, data):\n",
        "\n",
        "    self.data = data\n",
        "\n",
        "    # configure the optimizer\n",
        "    self.optimiser = model.configureOptimiser()\n",
        "    self.model = model\n",
        "\n",
        "    for epoch in range(self.maxEpochs):\n",
        "      print(\"Epoch: \", epoch + 1)\n",
        "      self.fitEpoch()\n",
        "      self.model.lr = self.expLR(self.model.lr)\n",
        "\n",
        "    print(\"Training process has finished\")\n",
        "\n",
        "  def fitEpoch(self):\n",
        "    currentLoss = 0.0\n",
        "\n",
        "    for i, data in enumerate(self.data):\n",
        "      # Get input aand its corresponding groundtruth output\n",
        "      inputs, target = data\n",
        "\n",
        "      self.optimiser.zero_grad()\n",
        "\n",
        "      # get output from the model, given the inputs\n",
        "      outputs = self.model(inputs)\n",
        "\n",
        "      # get loss for the predicted output\n",
        "      loss = self.model.loss(outputs, target)\n",
        "\n",
        "      # get gradients w.r.t the parameters of the model\n",
        "      loss.backward()\n",
        "\n",
        "      # update the parameters (perform optimization)\n",
        "      self.optimiser.step()\n",
        "\n",
        "      currentLoss += loss.item()\n",
        "      if i % 10 == 9:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, currentLoss / 10))\n",
        "          currentLoss = 0.0\n",
        "\n",
        "  def evaluate(self, model, data):\n",
        "    allCorrect = 0\n",
        "    for images, labels in data:\n",
        "      outputs = model(images)\n",
        "      estLabel = torch.max(outputs, 1).indices\n",
        "      correct = sum(estLabel == labels)\n",
        "      allCorrect += correct\n",
        "    print(\"Correct: \", allCorrect, \"Total: \", len(data) * data.batch_size)"
      ],
      "metadata": {
        "id": "JtL1UCCmOLSK"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "trainSet = DataLoader().load(dataset=\"/train\", batchSize=34, shuffle=True, workers=2)\n",
        "model = MLP(lr=1e-02)\n",
        "trainer = Trainer(nEpochs=10)\n",
        "trainer.fit(model, trainSet)\n",
        "trainer.evaluate(model=model, data=trainSet)"
      ],
      "metadata": {
        "id": "pjZbfGugN648"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "def imgShow(img):\n",
        "    img = img / 2 + 0.5 # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "validloader = DataLoader().load(dataset=\"/valid\", batchSize=10, shuffle=True, workers=2)\n",
        "classes = validloader.dataset.classes\n",
        "\n",
        "dataiter = iter(validloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imgShow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(images.shape[0])))\n",
        "\n",
        "output = model(images)\n",
        "estimatedLabels = torch.max(output, 1).indices\n",
        "\n",
        "print('Estimated Labels: ', ' '.join(f'{classes[estimatedLabels[j]]:5s}' for j in range(images.shape[0])))\n",
        "\n",
        "trainer.evaluate(model=model, data=validloader)"
      ],
      "metadata": {
        "id": "XB1tsjsDmcDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}