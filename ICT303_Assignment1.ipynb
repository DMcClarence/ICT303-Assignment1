{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/DMcClarence/ICT303-Assignment1/blob/main/ICT303_Assignment1.ipynb",
      "authorship_tag": "ABX9TyPIeKn2Z3uZxn+pwdaGkTXU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sErBd01nhySo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520d6625-7d72-4831-d396-e3f77f93a183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Set Up\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loader\n",
        "class DataLoader():\n",
        "  def __init__(self, dir=\"MyDrive/data\", width=300, height=432):\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.root = dir\n",
        "\n",
        "  def load(self, dataset=\"/valid\", batchSize=10, shuffle=True, workers=2):\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    dataset = datasets.ImageFolder(root=self.root + dataset, transform=transform)\n",
        "    self.dataset = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=shuffle, num_workers=workers)\n",
        ""
      ],
      "metadata": {
        "id": "Hz6eIOSv9AIG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, inputSize=32 * 32 * 3, outputSize=10, lr=0.01):\n",
        "    super.__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "\n",
        "    )\n",
        "\n",
        "    self.lr = lr\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)\n",
        "\n",
        "  def loss(self, y, y_hat):\n",
        "    fn = nn.CrossEntropyLoss()\n",
        "    return fn(y_hat, y)\n",
        "\n",
        "  def configureOptimiser(self):\n",
        "    return torch.optim.Adam(self.parameters(), self.lr)"
      ],
      "metadata": {
        "id": "6VGMRhXnlKFi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer Class\n",
        "class Trainer():\n",
        "  def __init__(self, nEpochs=3):\n",
        "    self.maxEpochs = nEpochs\n",
        "    return\n",
        "\n",
        "  # The fitting step\n",
        "  def fit(self, model, data):\n",
        "\n",
        "    self.data = data\n",
        "\n",
        "    # configure the optimizer\n",
        "    self.optimiser = model.configureOptimiser()\n",
        "    self.model = model\n",
        "\n",
        "    for epoch in range(self.max_epochs):\n",
        "      self.fit_epoch()\n",
        "\n",
        "    print(\"Training process has finished\")\n",
        "\n",
        "  def fitEpoch(self):\n",
        "    currentLoss = 0.0\n",
        "\n",
        "    for i, data in enumerate(self.data):\n",
        "      # Get input aand its corresponding groundtruth output\n",
        "      inputs, target = data\n",
        "\n",
        "      self.optimiser.zero_grad()\n",
        "\n",
        "      # get output from the model, given the inputs\n",
        "      outputs = self.model(inputs)\n",
        "\n",
        "      # get loss for the predicted output\n",
        "      loss = self.model.loss(outputs, target)\n",
        "\n",
        "      # get gradients w.r.t the parameters of the model\n",
        "      loss.backward()\n",
        "\n",
        "      # update the parameters (perform optimization)\n",
        "      self.optimiser.step()\n",
        "\n",
        "      # Let's print some statisics\n",
        "      currentLoss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, currentLoss / 500))\n",
        "          currentLoss = 0.0"
      ],
      "metadata": {
        "id": "JtL1UCCmOLSK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = DataLoader().load(dataset=\"/train\", batchSize=10, shuffle=True, workers=2)\n",
        "model = MLP(lr=1e-04)\n",
        "trainer = Trainer(nEpochs=3)\n",
        "trainer.fit(model, trainSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "pjZbfGugN648",
        "outputId": "6f4fb482-bd96-4428-905b-05c8cdcb9a92"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "descriptor '__init__' of 'super' object needs an argument",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2385318682.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainSet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1201876891.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputSize, outputSize, lr)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputSize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     self.net = nn.Sequential(\n",
            "\u001b[0;31mTypeError\u001b[0m: descriptor '__init__' of 'super' object needs an argument"
          ]
        }
      ]
    }
  ]
}