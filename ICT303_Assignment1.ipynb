{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/DMcClarence/ICT303-Assignment1/blob/main/ICT303_Assignment1.ipynb",
      "authorship_tag": "ABX9TyMHUGM9u4NIt9Msqu981GlD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sErBd01nhySo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc550f9-5c69-4772-ddfc-c520d711feeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Set Up\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loader\n",
        "class DataLoader():\n",
        "  def __init__(self, dir=\"MyDrive/data\", width=300, height=432):\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.root = dir\n",
        "\n",
        "  def load(self, dataset=\"/valid\", batchSize=10, shuffle=True, workers=2):\n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    dataset = datasets.ImageFolder(root=self.root + dataset, transform=transform)\n",
        "    dataset = torch.utils.data.DataLoader(dataset, batch_size=batchSize, shuffle=shuffle, num_workers=workers)\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "Hz6eIOSv9AIG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, inputSize=300*432*3, outputSize=8, lr=0.01):\n",
        "    super().__init__()\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "\n",
        "    )\n",
        "\n",
        "    self.lr = lr\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.net(X)\n",
        "\n",
        "  def loss(self, y_hat, y):\n",
        "    # print(y, y_hat)\n",
        "    fn = nn.CrossEntropyLoss()\n",
        "    return fn(y_hat, y)\n",
        "\n",
        "  def configureOptimiser(self):\n",
        "    return torch.optim.Adam(self.parameters(), self.lr)"
      ],
      "metadata": {
        "id": "6VGMRhXnlKFi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer Class\n",
        "class Trainer():\n",
        "  def __init__(self, nEpochs=3):\n",
        "    self.maxEpochs = nEpochs\n",
        "\n",
        "  # The fitting step\n",
        "  def fit(self, model, data):\n",
        "\n",
        "    self.data = data\n",
        "\n",
        "    # configure the optimizer\n",
        "    self.optimiser = model.configureOptimiser()\n",
        "    self.model = model\n",
        "\n",
        "    for epoch in range(self.maxEpochs):\n",
        "      self.fitEpoch()\n",
        "\n",
        "    print(\"Training process has finished\")\n",
        "\n",
        "  def fitEpoch(self):\n",
        "    currentLoss = 0.0\n",
        "\n",
        "    for i, data in enumerate(self.data):\n",
        "      # Get input aand its corresponding groundtruth output\n",
        "      inputs, target = data\n",
        "\n",
        "      self.optimiser.zero_grad()\n",
        "\n",
        "      # get output from the model, given the inputs\n",
        "      outputs = self.model(inputs)\n",
        "\n",
        "      # get loss for the predicted output\n",
        "      loss = self.model.loss(outputs, target)\n",
        "\n",
        "      # get gradients w.r.t the parameters of the model\n",
        "      loss.backward()\n",
        "\n",
        "      # update the parameters (perform optimization)\n",
        "      self.optimiser.step()\n",
        "\n",
        "      # Let's print some statisics\n",
        "      currentLoss += loss.item()\n",
        "      if i % 500 == 499:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, currentLoss / 500))\n",
        "          currentLoss = 0.0"
      ],
      "metadata": {
        "id": "JtL1UCCmOLSK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainSet = DataLoader().load(dataset=\"/train\", batchSize=16, shuffle=True, workers=2)\n",
        "model = MLP(lr=1e-04)\n",
        "trainer = Trainer(nEpochs=3)\n",
        "trainer.fit(model, trainSet)"
      ],
      "metadata": {
        "id": "pjZbfGugN648"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}